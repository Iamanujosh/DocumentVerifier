{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fda1c88-18ac-4912-a430-8ebd3bdb0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904aa4c7-5086-4ba3-88ec-34e01eb3c350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "x_data = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "y_data = pd.DataFrame(data.target, columns=['Targets'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bf28845-3c36-4310-b78e-b5a7203035bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                5.1               3.5                1.4               0.2\n",
       "1                4.9               3.0                1.4               0.2\n",
       "2                4.7               3.2                1.3               0.2\n",
       "3                4.6               3.1                1.5               0.2\n",
       "4                5.0               3.6                1.4               0.2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fedb52a8-17bf-4ac6-80d1-5d30225035ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data,y_data, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57eb16f9-d647-4d8b-aa52-897af713cfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9a37308-da48-49d0-a5b9-44b6f02a8593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anushka\\AppData\\Roaming\\Python\\Python313\\site-packages\\sklearn\\base.py:1389: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80b0c24-47af-4513-8d31-d8afc085f927",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ed954ab-ebe5-4dec-a0b9-1c4188e67508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebceb78c-7bc6-47f2-aa2c-b3b13f69b678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./../savedModels/models.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(model,'./../savedModels/models.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5203623e-a8a7-45c9-acd5-a828380a09aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset downloaded successfully!\n",
      "‚úÖ Training & testing datasets created successfully!\n",
      "‚úÖ Successfully added 50 fake samples to the training dataset!\n",
      "‚úÖ Successfully added 13 fake samples to the test dataset!\n",
      "üéØ Model Accuracy: 69.23%\n",
      "‚úÖ Model training completed!\n",
      "Prediction Probabilities: [0.55 0.45]\n",
      "thissssss ‚úÖ Real Document\n",
      "‚úÖ Report saved as document_verification_report.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import kagglehub\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from PIL import Image, ImageChops, ImageEnhance\n",
    "import piexif\n",
    "import joblib\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle\n",
    "from reportlab.lib.units import inch\n",
    "from reportlab.lib import colors\n",
    "from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image as RLImage, Table, TableStyle\n",
    "from reportlab.platypus.flowables import HRFlowable\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ====================== DATA DOWNLOAD AND PREPROCESSING ======================\n",
    "\n",
    "def download_dataset():\n",
    "    \"\"\"Download the dataset from Kaggle.\"\"\"\n",
    "    path = kagglehub.dataset_download(\"adisharmaruda/doc-classifier\")\n",
    "    dataset_path = path  # Use the downloaded path\n",
    "    print(\"‚úÖ Dataset downloaded successfully!\")\n",
    "    return dataset_path\n",
    "\n",
    "# Define categories\n",
    "categories = {\"aadhar-card\": 0, \"pan-card\": 0, \"fake-docs\": 1}  # 0: Real, 1: Fake\n",
    "\n",
    "# ====================== FEATURE EXTRACTION FUNCTIONS ======================\n",
    "\n",
    "def extract_ela(image_path):\n",
    "    \"\"\"Extract Error Level Analysis (ELA) feature.\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image.save(\"temp.jpg\", \"JPEG\", quality=90)\n",
    "        temp_image = Image.open(\"temp.jpg\")\n",
    "        ela_image = ImageChops.difference(image, temp_image)\n",
    "        extrema = ela_image.getextrema()\n",
    "        max_diff = max([ex[1] for ex in extrema])\n",
    "        return max_diff\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def extract_metadata(image_path):\n",
    "    \"\"\"Extract metadata from image.\"\"\"\n",
    "    try:\n",
    "        exif_data = piexif.load(image_path)\n",
    "        date_time = exif_data[\"0th\"].get(piexif.ImageIFD.DateTime, b'').decode()\n",
    "        return 1 if date_time else 0\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def extract_features(image_path):\n",
    "    \"\"\"Extract all features from an image.\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    img_resized = cv2.resize(img, (224, 224))  # Resize for consistency\n",
    "    mean_r, mean_g, mean_b = np.mean(img[:, :, 0]), np.mean(img[:, :, 1]), np.mean(img[:, :, 2])\n",
    "    std_r, std_g, std_b = np.std(img[:, :, 0]), np.std(img[:, :, 1]), np.std(img[:, :, 2])\n",
    "\n",
    "    # Extract additional features\n",
    "    ela_value = extract_ela(image_path)\n",
    "    metadata_value = extract_metadata(image_path)\n",
    "\n",
    "    # Flatten pixel values\n",
    "    img_flatten = img_resized.flatten()[:1024]  # Use first 1024 pixels\n",
    "    features = np.hstack([mean_r, std_r, mean_g, std_g, mean_b, std_b, ela_value, metadata_value, img_flatten])\n",
    "\n",
    "    return features\n",
    "\n",
    "# ====================== DATASET CREATION ======================\n",
    "\n",
    "def create_dataset(dataset_path):\n",
    "    \"\"\"Create dataset from downloaded images.\"\"\"\n",
    "    data = []\n",
    "    for category, label in categories.items():\n",
    "        folder_path = os.path.join(dataset_path, category)\n",
    "        if os.path.exists(folder_path):\n",
    "            for filename in os.listdir(folder_path):\n",
    "                image_path = os.path.join(folder_path, filename)\n",
    "                features = extract_features(image_path)\n",
    "                if features is not None:\n",
    "                    data.append([image_path] + list(features) + [label])\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    columns = [\"image_path\", \"mean_r\", \"std_r\", \"mean_g\", \"std_g\", \"mean_b\", \"std_b\", \"ela_value\", \"metadata_value\"] + [f\"feat_{i}\" for i in range(1024)] + [\"label\"]\n",
    "    df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "    # Split Data into Training & Testing\n",
    "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Save datasets\n",
    "    train_df.to_csv(\"train_dataset.csv\", index=False)\n",
    "    test_df.to_csv(\"test_dataset.csv\", index=False)\n",
    "\n",
    "    print(\"‚úÖ Training & testing datasets created successfully!\")\n",
    "    return train_df, test_df\n",
    "\n",
    "# ====================== DATA AUGMENTATION ======================\n",
    "\n",
    "def generate_fake_data(df, num_samples=None):\n",
    "    \"\"\"Generate fake samples by adding noise to real data.\"\"\"\n",
    "    fake_data = df.copy()\n",
    "\n",
    "    # Apply random noise to numerical features (excluding label column)\n",
    "    feature_cols = fake_data.columns[1:-1]  # Exclude 'image_path' and 'label'\n",
    "\n",
    "    for col in feature_cols:\n",
    "        fake_data[col] += np.random.normal(0, 0.05, size=fake_data.shape[0])  # Add small noise\n",
    "\n",
    "    # Change label to 'fake' (1)\n",
    "    fake_data[\"label\"] = 1\n",
    "\n",
    "    # Limit number of generated fake samples if needed\n",
    "    if num_samples:\n",
    "        fake_data = fake_data.sample(n=num_samples, random_state=42, replace=True)\n",
    "\n",
    "    return fake_data\n",
    "\n",
    "def augment_data(train_df, test_df):\n",
    "    \"\"\"Augment the dataset with fake samples.\"\"\"\n",
    "    # Generate fake samples (same count as real ones)\n",
    "    train_fake = generate_fake_data(train_df, num_samples=len(train_df))\n",
    "    test_fake = generate_fake_data(test_df, num_samples=len(test_df))\n",
    "\n",
    "    # Merge fake data with original datasets\n",
    "    train_augmented = pd.concat([train_df, train_fake], axis=0, ignore_index=True)\n",
    "    test_augmented = pd.concat([test_df, test_fake], axis=0, ignore_index=True)\n",
    "\n",
    "    # Save updated datasets\n",
    "    train_augmented.to_csv(\"train_dataset_augmented.csv\", index=False)\n",
    "    test_augmented.to_csv(\"test_dataset_augmented.csv\", index=False)\n",
    "\n",
    "    print(f\"‚úÖ Successfully added {len(train_fake)} fake samples to the training dataset!\")\n",
    "    print(f\"‚úÖ Successfully added {len(test_fake)} fake samples to the test dataset!\")\n",
    "    return train_augmented, test_augmented\n",
    "\n",
    "# ====================== MODEL TRAINING ======================\n",
    "\n",
    "def train_model(train_df, test_df):\n",
    "    \"\"\"Train the Random Forest classifier.\"\"\"\n",
    "    # Separate features and labels\n",
    "    X_train = train_df.drop(columns=[\"image_path\", \"label\"], errors='ignore')\n",
    "    y_train = train_df[\"label\"].astype('category').cat.codes  # Convert labels to numbers\n",
    "    X_test = test_df.drop(columns=[\"image_path\", \"label\"], errors='ignore')\n",
    "    y_test = test_df[\"label\"].astype('category').cat.codes\n",
    "\n",
    "    # Train the Random Forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"üéØ Model Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Save trained model\n",
    "    joblib.dump(model,'./../savedModels/train_models.joblib')\n",
    "    print(\"‚úÖ Model training completed!\")\n",
    "    return model\n",
    "\n",
    "# ====================== FORGERY DETECTION ======================\n",
    "\n",
    "def check_forgery(image_path, model, feature_columns):\n",
    "    \"\"\"Check if a document is forged using the trained model.\"\"\"\n",
    "    features = extract_features(image_path)  # Extract features from the image\n",
    "    if features is None:\n",
    "        return \"‚ö†Ô∏è Error: Unable to extract features from image.\", None\n",
    "\n",
    "    # Convert to DataFrame and match feature columns\n",
    "    feature_df = pd.DataFrame([features], columns=feature_columns)\n",
    "\n",
    "    # Predict using the trained model\n",
    "    prediction_proba = model.predict_proba(feature_df)[0]\n",
    "    print(f\"Prediction Probabilities: {prediction_proba}\")  # Debugging output\n",
    "\n",
    "    result = \"‚ùå Fake Document\" if prediction_proba[1] > 0.45 else \"‚úÖ Real Document\"\n",
    "    return result, prediction_proba\n",
    "\n",
    "# ====================== REPORT GENERATION ======================\n",
    "\n",
    "def apply_ela(image_path, quality=90):\n",
    "    \"\"\"Apply Error Level Analysis (ELA) to detect forgery.\"\"\"\n",
    "    original = Image.open(image_path).convert('RGB')\n",
    "    temp_path = \"temp_compressed.jpg\"\n",
    "    original.save(temp_path, 'JPEG', quality=quality)\n",
    "    compressed = Image.open(temp_path)\n",
    "\n",
    "    ela_image = ImageChops.difference(original, compressed)\n",
    "    extrema = ela_image.getextrema()\n",
    "    max_diff = max([ex[1] for ex in extrema])\n",
    "    scale = 255.0 / max_diff if max_diff else 1\n",
    "    ela_image = ImageEnhance.Brightness(ela_image).enhance(scale)\n",
    "\n",
    "    ela_path = \"ela_output.png\"\n",
    "    ela_image.save(ela_path)\n",
    "    return ela_path\n",
    "\n",
    "def extract_metadata_for_report(image_path):\n",
    "    \"\"\"Extract metadata information from the image (if available).\"\"\"\n",
    "    try:\n",
    "        exif_data = Image.open(image_path)._getexif()\n",
    "        if exif_data:\n",
    "            metadata = {\n",
    "                key: exif_data[key] for key in exif_data if key in [306, 271, 272]  # DateTime, Camera Make & Model\n",
    "            }\n",
    "            return metadata if metadata else 0  # Return 0 instead of \"No Metadata Found\"\n",
    "        return 0  # If no metadata is found, return numerical 0\n",
    "    except:\n",
    "        return 0  # Ensure numeric return value\n",
    "\n",
    "def generate_verification_report(image_path, prediction_proba, result):\n",
    "    \"\"\"Generate a professional PDF report for document verification with ELA, Metadata, and Charts.\"\"\"\n",
    "    report_name = \"document_verification_report.pdf\"\n",
    "    doc = SimpleDocTemplate(report_name, pagesize=letter,\n",
    "                           rightMargin=72, leftMargin=72,\n",
    "                           topMargin=72, bottomMargin=18)\n",
    "\n",
    "    # Determine if the document is fake based on the result string\n",
    "    is_fake = \"‚ùå\" in result #change\n",
    "    status = \"FORGED\" if is_fake else \"GENUINE\"\n",
    "\n",
    "    # Styles\n",
    "    styles = getSampleStyleSheet()\n",
    "    title_style = styles['Title']\n",
    "    heading_style = styles['Heading1']\n",
    "    normal_style = styles['Normal']\n",
    "\n",
    "    # Custom styles\n",
    "    section_style = ParagraphStyle(\n",
    "        'Section',\n",
    "        parent=styles['Heading2'],\n",
    "        spaceAfter=12,\n",
    "        textColor=colors.darkblue\n",
    "    )\n",
    "\n",
    "    # Build the document\n",
    "    elements = []\n",
    "\n",
    "    # Title\n",
    "    elements.append(Paragraph(\"Document Verification Report\", title_style))\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # Document Details\n",
    "    elements.append(Paragraph(\"Document Details\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "\n",
    "    # Create a table for document details\n",
    "    data = [\n",
    "        [\"Document Name:\", os.path.basename(image_path)],\n",
    "        [\"Verification Date:\", datetime.now().strftime('%Y-%m-%d %H:%M:%S')],\n",
    "        [\"Forgery Status:\", status],\n",
    "        [\"Detection Result:\", result]  # Added the actual result with emoji\n",
    "    ]\n",
    "\n",
    "    # Add the original image\n",
    "    elements.append(Spacer(1, 0.15*inch))\n",
    "    elements.append(Paragraph(\"Original Document\", section_style))\n",
    "\n",
    "    # Include the original image with a maximum width of 5 inches\n",
    "    img = Image.open(image_path)\n",
    "    img_width, img_height = img.size\n",
    "    aspect_ratio = img_height / img_width\n",
    "    img_width = 5 * inch\n",
    "    img_height = img_width * aspect_ratio\n",
    "\n",
    "    img_path = \"original_resized.jpg\"\n",
    "    img.save(img_path)\n",
    "    elements.append(RLImage(img_path, width=img_width, height=img_height))\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # Format the table\n",
    "    detail_table = Table(data, colWidths=[2*inch, 3.5*inch])\n",
    "    detail_table.setStyle(TableStyle([\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n",
    "        ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),\n",
    "        ('ALIGN', (0, 0), (0, -1), 'RIGHT'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(detail_table)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # Prediction Results\n",
    "    elements.append(Paragraph(\"Prediction Results\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "\n",
    "    # Generate Pie Chart\n",
    "    labels = [\"Real\", \"Fake\"]\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(prediction_proba, labels=labels, autopct='%1.1f%%',\n",
    "            colors=['#FF6B6B', '#4ECDC4'], startangle=140,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 2})\n",
    "    plt.title(\"Forgery Prediction Confidence\")\n",
    "    pie_chart_path = \"prediction_pie_chart.png\"\n",
    "    plt.savefig(pie_chart_path, bbox_inches='tight', dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "    # Add explanation about the threshold\n",
    "    elements.append(Paragraph(f\"Note: According to your model, a document is considered fake if the Real probability is greater than 40%.\", normal_style))\n",
    "    elements.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "    # Include the pie chart\n",
    "    elements.append(RLImage(pie_chart_path, width=4*inch, height=4*inch))\n",
    "    elements.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "    # Create a table for prediction probabilities\n",
    "    prob_data = [\n",
    "        [\"Prediction\", \"Confidence\"],\n",
    "        [\"Real\", f\"{prediction_proba[0]:.2%}\"],\n",
    "        [\"Fake\", f\"{prediction_proba[1]:.2%}\"]\n",
    "    ]\n",
    "\n",
    "    prob_table = Table(prob_data, colWidths=[2*inch, 2*inch])\n",
    "    prob_table.setStyle(TableStyle([\n",
    "        ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n",
    "        ('BACKGROUND', (0, 0), (-1, 0), colors.lightgrey),\n",
    "        ('ALIGN', (0, 0), (-1, -1), 'CENTER'),\n",
    "        ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "        ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),\n",
    "        ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "        ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "        ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "    ]))\n",
    "    elements.append(prob_table)\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # Error Level Analysis\n",
    "    elements.append(Paragraph(\"Error Level Analysis (ELA)\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "    elements.append(Paragraph(\"ELA highlights differences in compression levels. Areas with higher error levels may indicate manipulation.\", normal_style))\n",
    "    elements.append(Spacer(1, 0.15*inch))\n",
    "\n",
    "    # Apply ELA and add to report\n",
    "    ela_path = apply_ela(image_path)\n",
    "    elements.append(RLImage(ela_path, width=5*inch, height=3*inch))\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "\n",
    "    # Extract Metadata\n",
    "    elements.append(Paragraph(\"Metadata Information\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "\n",
    "    metadata = extract_metadata_for_report(image_path)\n",
    "    if isinstance(metadata, dict) and metadata:\n",
    "        metadata_rows = []\n",
    "        for key, value in metadata.items():\n",
    "            metadata_rows.append([str(key), str(value)])\n",
    "\n",
    "        metadata_table = Table(metadata_rows, colWidths=[2*inch, 3.5*inch])\n",
    "        metadata_table.setStyle(TableStyle([\n",
    "            ('GRID', (0, 0), (-1, -1), 0.5, colors.grey),\n",
    "            ('BACKGROUND', (0, 0), (0, -1), colors.lightgrey),\n",
    "            ('ALIGN', (0, 0), (0, -1), 'RIGHT'),\n",
    "            ('VALIGN', (0, 0), (-1, -1), 'MIDDLE'),\n",
    "            ('FONTNAME', (0, 0), (0, -1), 'Helvetica-Bold'),\n",
    "            ('FONTSIZE', (0, 0), (-1, -1), 10),\n",
    "            ('BOTTOMPADDING', (0, 0), (-1, -1), 8),\n",
    "            ('TOPPADDING', (0, 0), (-1, -1), 8),\n",
    "        ]))\n",
    "        elements.append(metadata_table)\n",
    "    else:\n",
    "        elements.append(Paragraph(\"No metadata found in the image.\", normal_style))\n",
    "\n",
    "    # Conclusion\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "    elements.append(Paragraph(\"Conclusion\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "\n",
    "    conclusion_text = f\"Based on our analysis, this document appears to be {status}.\"\n",
    "    elements.append(Paragraph(conclusion_text, normal_style))\n",
    "\n",
    "    if is_fake:\n",
    "        elements.append(Paragraph(\"The document shows signs of digital manipulation. Please review the ELA analysis and prediction probabilities for more details.\", normal_style))\n",
    "    else:\n",
    "        elements.append(Paragraph(\"No significant signs of digital manipulation were detected. However, this analysis is not conclusive and should be combined with other verification methods.\", normal_style))\n",
    "\n",
    "    # Add disclaimer\n",
    "    elements.append(Spacer(1, 0.25*inch))\n",
    "    elements.append(Paragraph(\"Disclaimer\", section_style))\n",
    "    elements.append(HRFlowable(width=\"100%\", thickness=1, color=colors.darkblue, spaceAfter=10))\n",
    "    disclaimer_text = \"This report is generated by an automated system and should be used for informational purposes only. The results are based on digital analysis and may not be 100% accurate. For legal or critical verification, please consult with a forensic document examiner.\"\n",
    "    elements.append(Paragraph(disclaimer_text, normal_style))\n",
    "\n",
    "    # Build the document\n",
    "    doc.build(elements)\n",
    "    print(f\"‚úÖ Report saved as {report_name}\")\n",
    "    return report_name\n",
    "\n",
    "# ====================== MAIN EXECUTION ======================\n",
    "\n",
    "def main():\n",
    "    # Step 1: Download dataset\n",
    "    dataset_path = download_dataset()\n",
    "\n",
    "    # Step 2: Create and split dataset\n",
    "    train_df, test_df = create_dataset(dataset_path)\n",
    "\n",
    "    # Step 3: Augment data with fake samples\n",
    "    train_augmented, test_augmented = augment_data(train_df, test_df)\n",
    "\n",
    "    # Step 4: Train model\n",
    "    model = train_model(train_augmented, test_augmented)\n",
    "\n",
    "    # Step 5: Test with a sample image\n",
    "    test_image_path = \"./adh.jpg\"  \n",
    "\n",
    "    # Load feature columns (needed for prediction)\n",
    "    X_train = train_augmented.drop(columns=[\"image_path\", \"label\"], errors='ignore')\n",
    "\n",
    "    # Check forgery\n",
    "    result, prediction_proba = check_forgery(test_image_path, model, X_train.columns)\n",
    "    print(\"thissssss\",result)\n",
    "    \n",
    "    # Generate report\n",
    "    generate_verification_report(test_image_path, prediction_proba, result)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a619688-aa3c-40b6-a410-a0f91d558eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
